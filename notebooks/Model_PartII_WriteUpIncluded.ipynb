{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luiata Data Science Take-home Assignment - Part II: Modeling\n",
    "\n",
    "### Jade Yun | [LinkedIn](https://www.linkedin.com/in/jadeyun/) | [GitHub](https://github.com/yuyun2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook contains code for:\n",
    "- Baseline model (Random Forest)\n",
    "- Fine tune Random Forest Model using GridSearchCV\n",
    "- RF on variables with high importance\n",
    "- Gradient Boosting model using LightGBM\n",
    "- Fine tune LightGBM Model using GridSearchCV\n",
    "- Emsemble\n",
    "- Understand Feature Importance\n",
    "\n",
    "**Precision-Recall AUC (PRAUC)** is selected as metric of model performance. \n",
    "\n",
    "At each step, model performance is evaluated based on validation set. \n",
    "\n",
    "Precision@20Recall and AUC are also calculated for reference only."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this assignment, machine learning models are built to predict patients' claim in the next year using patients medical history data.\n",
    "\n",
    "Features are built from 3 perspectives to characterize patients medical status:\n",
    "1. Patients' geographical informaiton (i.e. age, gender)\n",
    "2. Patients' doctor visit behavior (e.g. # of visits, # of visits within time window, # of specific medical procedures, # of days since last/first visits)\n",
    "3. Patients' lab results (e.g. # of lab tests, # of lab tests within time window, avg value of specific tests, value of last test)\n",
    "\n",
    "In 2 and 3, apart from macro behaviors like total # of visits, total # of lab tests, etc, patient history on some certain important resource codes and lab tests are calculated as well. \n",
    "\n",
    "To understand the relationship between dabetes and each resource code/lab code, patient claim rate is calcualted for each resource code and lab code. For the top ranked resource code and lab code, features are calculated as described in 2 and 3, code and more detailed explanation can be found in the part I notebook. Claim rate itself is not used as feature to prevent data leakage.\n",
    "\n",
    "Before modeling, the data set is split into 3 parts: train, validation and test:\n",
    "\n",
    "- Train set is used to train model and tune hyper-parameters\n",
    "- Validation set works as held-out data to evaluate model performance\n",
    "- Test set contains the data needs to be predicted\n",
    "\n",
    "Modeling proecess (Precision-Recall AUC (PRAUC) on validation set is reported at each step) is: \n",
    "\n",
    "1. Baseline Random Forest model (no hyper-parameter tuning), PRAUC: 0.174\n",
    "2. Random Forest on feature subset (high importance features from step 1), PRAUC: 0.174, no improvement\n",
    "3. Random Forest tuned with GridSearchCV, PRAUC: 0.183\n",
    "4. LightGBM model (no hyper-parameter tuning), PRAUC: 0.188\n",
    "5. LightGBM model tuned with GridSearchCV, PRAUC: 0.193\n",
    "6. Ensemble (Average of tuned Random Forest and LightGBM), PRAUC: 0.193, no improvement\n",
    "\n",
    "In the modeling process, to prevent overfitting, cross-validation is used on train set.\n",
    "\n",
    "Fine-tuned LightGBM is selected as final model, the full dataset (train+validation) is used to train the final model and then to predict test set.\n",
    "\n",
    "Lastly, feature importance from both Random Forest and Light GBM. The top 5 most important features are:\n",
    "\n",
    "1. Age, this is in accordance with research by American Diabetes Association.\n",
    "\n",
    "2. Average value of test loinc_4548-4, which tests the patients Hemoglobin level in blood.\n",
    "\n",
    "3. Number of days since last resource code cpt_83036. This is also related with Hemoglobin level.\n",
    "\n",
    "4. Number of resource code icd10_I10. The code is related with hypertension, which is the most common comorbid condition in diabetes.\n",
    "\n",
    "5. Number of days since last doctor visit. A recent doctor visit might indicate a claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumiata = create_engine('sqlite:///lumiata.db') # connect to sqlite database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic patient and claim information\n",
    "base = pd.read_sql_query('SELECT * FROM basic_info', lumiata) # query from base table\n",
    "\n",
    "# features about resource\n",
    "res_cnt = pd.read_sql_query('SELECT * FROM res_num_visit', lumiata) # query from base table\n",
    "res_onehot = pd.read_sql_query('SELECT * FROM res_one_hot', lumiata)\n",
    "res_days = pd.read_sql_query('SELECT * FROM res_days', lumiata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features about observation\n",
    "ob_cnt = pd.read_sql_query('SELECT * FROM obs_num_labs', lumiata)\n",
    "ob_onehot = pd.read_sql_query('SELECT * FROM ob_one_hot', lumiata)\n",
    "ob_last = pd.read_sql_query('SELECT * FROM last_ob_one_hot', lumiata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all the tables together\n",
    "dfs = [base, res_cnt, res_onehot, res_days, ob_cnt, ob_onehot, ob_last]\n",
    "master = reduce(lambda left,right: pd.merge(left,right,on='patient_id',how='left'), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create age\n",
    "master['age'] = (pd.to_datetime('2016-12-31') - pd.to_datetime(master['birthday']))/(12*np.timedelta64(1, 'M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    \"\"\"split master data into train, validation and test set\n",
    "    \"\"\"\n",
    "    df['claim'] = 0       # create a new column for target\n",
    "    #df['random'] = np.random.random(size=len(df))  # insert a column of random number to analyze feature importance\n",
    "    \n",
    "    tmp, test = df.loc[df['split'] == 'train'], df.loc[df['split'] == 'test']     # assign train & test\n",
    "    tmp = tmp.loc[(tmp['tag_dm2'].isnull()) | (tmp['tag_dm2'] >= '2017-01-01')]   # filter out 'prior' from train\n",
    "    \n",
    "    # label claim as 1 only if tag_dm2 is before 2017-12-31\n",
    "    tmp['claim'] = np.where(tmp['tag_dm2'] <= '2017-12-31', 1, 0)   \n",
    "    \n",
    "    # split train into train and validation 0.8/0.2\n",
    "    np.random.seed(0)\n",
    "    msk = np.random.rand(len(tmp)) < 0.8\n",
    "    train, valid = tmp[msk], tmp[~msk]\n",
    "    \n",
    "    print('observations in train/valid/test: {}/{}/{}'.format(train.shape[0], valid.shape[0], test.shape[0]))\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observations in train/valid/test: 58879/14641/31403\n"
     ]
    }
   ],
   "source": [
    "train, valid, test = split_df(master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf, df, features, plot_apr=False, target_recall=0.2, target='claim', fill_na=-1):\n",
    "    \"\"\" evaluate model performance, return:\n",
    "        - predictions (probablity)\n",
    "        - auc\n",
    "        - precision-recall auc\n",
    "        - precision @ target recall (default 0.2)\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(clf) is list:   # if a list of clfs is provided, calculate the average of all clfs prediction\n",
    "        pred = np.zeros(len(df))\n",
    "        for c in clf:     \n",
    "            pred += c.predict_proba(df[features].fillna(fill_na))[:,1]\n",
    "        pred = pred/len(clf)\n",
    "    else:\n",
    "        pred = clf.predict_proba(df[features].fillna(fill_na))[:,1]\n",
    "        \n",
    "    auc  = roc_auc_score(df[target], pred)\n",
    "    pr_auc = average_precision_score(df[target], pred)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(df[target], pred)\n",
    "    idx = (np.abs(recall - target_recall)).argmin()\n",
    "    pr_recall = precision[idx]    # precision at target recall\n",
    "    \n",
    "    if plot_apr:\n",
    "        \n",
    "        plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "        plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.title('Precision-Recall Curve: AP={0:0.2f}'.format(apr_auc))\n",
    "    \n",
    "    print(\"PRAUC: %.3f, Precision@%dRecall: %.3f, AUC: %.3f\" %(pr_auc, int(target_recall*100), pr_recall, auc))\n",
    "    \n",
    "    return pred, pr_auc, pr_recall, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_precision(labels, preds):\n",
    "    \"\"\"\n",
    "    http://lightgbm.readthedocs.io/en/latest/_modules/lightgbm/sklearn.html\n",
    "    self-defined eval metric for lightgbm\n",
    "    f(labels: array, preds: array) -> name: string, value: array, is_higher_better: bool\n",
    "    average precision (PRAUC)\n",
    "    \"\"\"\n",
    "    return 'pr_auc', average_precision_score(labels, preds), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(clf, features):\n",
    "    \"\"\"return ranked feature importance in pandas dataframe\n",
    "    \"\"\" \n",
    "    imp = pd.DataFrame({'feature': features,\n",
    "                        'importance': clf.feature_importances_}).sort_values('importance',ascending=False)\n",
    "    return imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "Use random forest classifier as a base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dedine response and dependent variables \n",
    "target = 'claim'\n",
    "\n",
    "base_cols = ['age','is_male']\n",
    "res_cols = [v for v in list(res_cnt)+list(res_onehot)+list(res_days) if v != 'patient_id']\n",
    "ob_cols = [v for v in list(ob_cnt)+list(ob_onehot)+list(ob_last) if v != 'patient_id']\n",
    "\n",
    "var = base_cols + res_cols + ob_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a random forest\n",
    "rfc = RandomForestClassifier(n_estimators=100,\n",
    "                             random_state=1,\n",
    "                             n_jobs=-1,\n",
    "                             min_samples_leaf = 50,\n",
    "                             oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=50, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=True, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(train[var].fillna(-1), train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Validation:\n",
      "PRAUC: 0.174, Precision@20Recall: 0.242, AUC: 0.783\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance on Validation:\")\n",
    "_ = evaluate_model(rfc, valid, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on Subset of Features\n",
    "\n",
    "Train a new random forest classifier using top 150 most important features to see if there is any improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get featuere importance\n",
    "feat_imp = get_feature_importance(rfc, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset top 150 most important features \n",
    "feat_subset = feat_imp.head(150)['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=50, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=True, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train rf again\n",
    "rfc.fit(train[feat_subset].fillna(-1), train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Validation:\n",
      "PRAUC: 0.174, Precision@20Recall: 0.220, AUC: 0.784\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance on Validation:\")\n",
    "_ = evaluate_model(rfc, valid, feat_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no improvement on precision-recall AUC. Continue to use all dependent in the following models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune Random Forest with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters grid\n",
    "param_grid = {\n",
    "    'max_features': ['auto', 10, 20],\n",
    "    'min_samples_leaf': [50, 100, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_rf = RandomForestClassifier(n_estimators=100,random_state=1,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = GridSearchCV(base_rf, param_grid, scoring='average_precision', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_features': ['auto', 10, 20], 'min_samples_leaf': [50, 100, 200]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='average_precision', verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best.fit(train[var].fillna(-1), train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 20, 'min_samples_leaf': 50}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg PRAUC of 3-fold CV on train set: 0.155\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg PRAUC of 3-fold CV on train set: %.3f\" %rf_best.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Validation:\n",
      "PRAUC: 0.183, Precision@20Recall: 0.233, AUC: 0.786\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance on Validation:\")\n",
    "_ = evaluate_model(rf_best, valid, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall AUC increased from 0.174 to 0.183 on validation set after fine tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize gradient boosting model\n",
    "gbm = lgb.LGBMClassifier(n_estimators=200,\n",
    "                         random_state=1,\n",
    "                         colsample_bytree=0.5,\n",
    "                         learning_rate=0.05,\n",
    "                         min_child_samples=50,\n",
    "                         subsample=0.9,\n",
    "                         objective='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds.\n",
      "[10]\ttrain's binary_logloss: 0.41846\ttrain's pr_auc: 0.209791\tvalid's binary_logloss: 0.419287\tvalid's pr_auc: 0.169956\n",
      "[20]\ttrain's binary_logloss: 0.299295\ttrain's pr_auc: 0.222562\tvalid's binary_logloss: 0.301013\tvalid's pr_auc: 0.174298\n",
      "[30]\ttrain's binary_logloss: 0.233251\ttrain's pr_auc: 0.236152\tvalid's binary_logloss: 0.235911\tvalid's pr_auc: 0.182064\n",
      "[40]\ttrain's binary_logloss: 0.199083\ttrain's pr_auc: 0.243126\tvalid's binary_logloss: 0.202561\tvalid's pr_auc: 0.185409\n",
      "[50]\ttrain's binary_logloss: 0.183553\ttrain's pr_auc: 0.255036\tvalid's binary_logloss: 0.188029\tvalid's pr_auc: 0.18454\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttrain's binary_logloss: 0.204573\ttrain's pr_auc: 0.24292\tvalid's binary_logloss: 0.207895\tvalid's pr_auc: 0.185413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.5,\n",
       "        learning_rate=0.05, max_depth=-1, min_child_samples=50,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=200,\n",
       "        n_jobs=-1, num_leaves=31, objective='binary', random_state=1,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=0.9,\n",
       "        subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "gbm.fit(train[var].fillna(-1), train[target],\n",
    "        eval_metric = avg_precision, \n",
    "        eval_names = ['train','valid'],\n",
    "        eval_set=[(train[var], train[target]), (valid[var], valid[target])],\n",
    "        early_stopping_rounds=20,\n",
    "        verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Validation:\n",
      "PRAUC: 0.188, Precision@20Recall: 0.253, AUC: 0.788\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance on Validation:\")\n",
    "_, auc_train, pr_auc_train, precision_r20_train = evaluate_model(gbm, valid, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall AUC increased from 0.183 to 0.188 on validation set using LightGBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune LightGBM with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize base GBM and define parameter grid\n",
    "base_gbm = lgb.LGBMClassifier(num_leaves=31)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [50, 100],\n",
    "    'colsample_bytree': [0.5, 0.8],\n",
    "    'min_child_samples': [50, 100],\n",
    "    'subsample': [0.8, 1]\n",
    "}\n",
    "\n",
    "best_gbm = GridSearchCV(base_gbm, param_grid, scoring='average_precision', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': [0.05, 0.1], 'n_estimators': [50, 100], 'colsample_bytree': [0.5, 0.8], 'min_child_samples': [50, 100], 'subsample': [0.8, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='average_precision', verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "best_gbm.fit(train[var].fillna(-1), train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'learning_rate': 0.05,\n",
       " 'min_child_samples': 50,\n",
       " 'n_estimators': 100,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show best parameters to use\n",
    "best_gbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRAUC on train 3-fold CV : 0.170\n"
     ]
    }
   ],
   "source": [
    "print(\"PRAUC on train 3-fold CV : %.3f\" %best_gbm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Validation:\n",
      "PRAUC: 0.193, Precision@20Recall: 0.253, AUC: 0.795\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance on Validation:\")\n",
    "_, auc_train, pr_auc_train, precision_r20_train = evaluate_model(best_gbm, valid, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall AUC increased from 0.188 to 0.193 after fine tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble\n",
    "\n",
    "Use the average of predictions from random forest and gbm, check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Validation:\n",
      "PRAUC: 0.193, Precision@20Recall: 0.242, AUC: 0.793\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance on Validation:\")\n",
    "_, auc_train, pr_auc_train, precision_r20_train = evaluate_model([best_gbm, rf_best], valid, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no improvement using emsemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chose gbm as final model, use optimal parameters found by grid search cv\n",
    "gbm_final = base_gbm.set_params(**best_gbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use full data set (train + validation) to train final model\n",
    "full_data = pd.concat([train, valid], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.5,\n",
       "        learning_rate=0.05, max_depth=-1, min_child_samples=50,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1,\n",
       "        subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_final.fit(full_data[var], full_data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "prediction = gbm_final.predict_proba(test[var])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put into data frame\n",
    "pred_df = pd.DataFrame({\"patient_id\": test['patient_id'],\n",
    "                        \"dm2_prob\"  : prediction})\n",
    "\n",
    "pred_df = pred_df[['patient_id', 'dm2_prob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write into csv\n",
    "pred_df.to_csv(\"./jadeyun_dm2_solution.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final = base_rf.set_params(**rf_best.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=20, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=50, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_final.fit(full_data[var].fillna(-1), full_data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feat_imp = get_feature_importance(rf_final, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.101332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>avg_loinc_4548_4</td>\n",
       "      <td>0.061449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>cnt_icd10_I10</td>\n",
       "      <td>0.030264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>d_first_icd10_I10</td>\n",
       "      <td>0.029156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>d_last_icd10_I10</td>\n",
       "      <td>0.027610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>d_first_visit</td>\n",
       "      <td>0.019600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>d_first_icd9_401_9</td>\n",
       "      <td>0.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>d_last_visit</td>\n",
       "      <td>0.018240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>num_visit_12mo</td>\n",
       "      <td>0.018083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>avg_loinc_27353_2</td>\n",
       "      <td>0.017795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>num_visit</td>\n",
       "      <td>0.017522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>d_first_icd</td>\n",
       "      <td>0.017066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_total_res</td>\n",
       "      <td>0.016676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>d_last_icd9_401_9</td>\n",
       "      <td>0.016526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>d_first_cpt</td>\n",
       "      <td>0.016347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature  importance\n",
       "0                   age    0.101332\n",
       "167    avg_loinc_4548_4    0.061449\n",
       "30        cnt_icd10_I10    0.030264\n",
       "98    d_first_icd10_I10    0.029156\n",
       "78     d_last_icd10_I10    0.027610\n",
       "68        d_first_visit    0.019600\n",
       "100  d_first_icd9_401_9    0.018913\n",
       "69         d_last_visit    0.018240\n",
       "21       num_visit_12mo    0.018083\n",
       "164   avg_loinc_27353_2    0.017795\n",
       "16            num_visit    0.017522\n",
       "72          d_first_icd    0.017066\n",
       "2         num_total_res    0.016676\n",
       "80    d_last_icd9_401_9    0.016526\n",
       "74          d_first_cpt    0.016347"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rf_feat_imp.head(10).plot.bar(x='feature')  # uncomment for visulization\n",
    "rf_feat_imp.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_feat_imp = get_feature_importance(gbm_final, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>d_last_visit</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>d_last_cpt_83036</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>v_last_loinc_4548_4</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>avg_loinc_4548_4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_total_res</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>num_visit</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>d_first_icd9_401_9</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>d_first_icd10_R73_09</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>d_first_icd10_I10</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>num_visit_12mo</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>d_last_icd10_E66_01</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>d_last_icd</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>d_last_icd10_I10</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>d_first_icd10_E66_01</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feature  importance\n",
       "0                     age         176\n",
       "69           d_last_visit          87\n",
       "76       d_last_cpt_83036          87\n",
       "182   v_last_loinc_4548_4          74\n",
       "167      avg_loinc_4548_4          60\n",
       "2           num_total_res          52\n",
       "16              num_visit          52\n",
       "100    d_first_icd9_401_9          51\n",
       "106  d_first_icd10_R73_09          48\n",
       "98      d_first_icd10_I10          47\n",
       "21         num_visit_12mo          47\n",
       "90    d_last_icd10_E66_01          46\n",
       "73             d_last_icd          44\n",
       "78       d_last_icd10_I10          44\n",
       "110  d_first_icd10_E66_01          43"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gbm_feat_imp.head(10).plot.bar(x='feature')\n",
    "gbm_feat_imp.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
